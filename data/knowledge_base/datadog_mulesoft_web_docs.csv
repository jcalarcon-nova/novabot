question,answer,category,tags,priority
What is Datadog APM Connector and how does it work?,Datadog APM Connector OVERVIEW The Datadog APM Connector for Mule 4 applications helps to instrument Mule 4 applications either running on CloudHub or on-premises. In the Datadog APM Connector you will find: The Datadog Mule Integration 4 APM (DMI4APM) enhances the monitoring capabilities of your Mule applications by seamlessly integrating with Datadog's APM system. Our solution extends the functionality of Datadog's APM connector by adding Mule-specific operations that encapsulate application flows. These operations not only capture and send trace data to Datadog APM but also facilitate the propagation of these traces across Mule applications and APIs.,datadog-mulesoft-docs,"datadog,mulesoft,documentation,overview,apm,connector",high
What is CloudWatch Mule Integration and how does it work?,CloudWatch Mule Integration OVERVIEW Overview CloudWatch Mule Integration is an agent-based integration that collects metrics from MuleSoft products and uploads them onto Amazon CloudWatch. In the CloudWatch Mule Integration bundle you will find: 120+ You can use these metrics to take advantage of the out-of-the-box dashboards and monitors or you can create your own visualizations.,datadog-mulesoft-docs,"datadog,mulesoft,documentation,overview,cloudwatch,dashboard",high
How do I configure the service for CLOUDWATCH MULE INTEGRATION - Configuration | The Service?,"CLOUDWATCH MULE INTEGRATION - Configuration | The Service The service user permissions CloudWatch Mule Integration requires specific permissions on the MuleSoft Anypoint Platform to collect metrics. There are some common permissions that must be granted to be able to execute any API and others, specific, used by one or few APIs. - ### Exchange API : o Exchange Administrator This is only required to read data from Exchange. CloudWatch Mule Integration does not modify any asset. - #### CloudHub: o CloudHub Organization Admin This is only required to read data from CloudHub. CloudWatch Mule Integration does not modify any asset. o Read Alerts - #### ARM Rest Services o Read Applications o Read Servers - #### Access Management: o View Organization - ARM Monitoring Query: - #### Object Store: o Manage Application Data o Manage stores data - #### Object Store V2 Stats: o An administrator user This is only required to read data from Object Store V2 statistics. CloudWatch Mule Integration does not modify any asset. If these metrics are not desired, make sure you comment out this entry in the configuration file in instances. The integration does not modify in any manner the assets in Anypoint Platform , those permissions are for read-only. Full example Below is a complete configuration example (with fake credentials and ids): ```yaml init_config: hosts: anypoint: https://anypoint.mulesoft.com object_store_v2: https://object-store-us-east-1.anypoint.mulesoft.com object_store_v2_stats: https://object-store-stats.anypoint.mulesoft.com mule_server: http://localhost:9999 oauth_provider: https://anypoint.mulesoft.com/accounts/api/v2/oauth2/token client_id: 035715123cbc31a1234a43143213f3 client_secret: bAc2345678C34aFB1A12f5A245678 env_id: a3cc1234-4a24-125b-1a45-1c1aa13cad org_id: ac2345aa-cc13-1367-bca1-b12aa4aa api_key: 548f-1s52-2d5f4f4ed customer_key: a6a6-b5e854e5 connection_wait_time: 2 connection_attempts_num: 3 instances: min_collection_interval: 86400 threads: 32 api_filter: access_management min_collection_interval: 10 threads: 32 api_filter: arm_monitoring_query min_collection_interval: 10 threads: 32 api_filter: arm_mule_agent min_collection_interval: 10 threads: 32 api_filter: arm_rest_services min_collection_interval: 10 threads: 32 api_filter: cloudhub min_collection_interval: 86400 threads: 32 api_filter: exchange_experience min_collection_interval: 60 threads: 32 api_filter: insight min_collection_interval: 86400 threads: 32 api_filter: object_store min_collection_interval: 86400 threads: 32 api_filter: object_store_v2_stats ```",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,cloudwatch,monitoring",high
How do I configure CLOUDWATCH MULE INTEGRATION - Configuration?,"CLOUDWATCH MULE INTEGRATION - Configuration Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. The CloudWatch Mule Integration is a CloudWatch custom integration and it is configured through a conf.yml file located at /home/cmi- agent/iocs/conf/conf.yml in Linux systems The configuration in the conf.yml is divided into two parts: - init_config: A common part used by all the executions - instances A list of instances to be scheduled independently init_config This section contains the common configuration used by all the instance executions. It contains the following configurations: - hosts: Grouping of all the hosts' definitions needed to read the metrics out of the Anypoint Platform. Some hosts are specific to some APIs, if so, it is specified in the description: - anypoint: The Anypoint server host URL. It is preconfigured with https://anypoint.mulesoft.com but it could be different for EU or GOV Mule Regions, see https://docs.mulesoft.com/access-management/managing-users#prerequisites - object_store_v2: Object Store V2 server host URL. See https://docs.mulesoft.com/object-store/osv2-apis for the full list of available hosts. This host definition is used by the Object Store API. Example value: https://object-store-us-east-1.anypoint.mulesoft.com - Object Store V2: Object Store V2 Stats API. It is preconfigured with https://object-store-stats.anypoint.mulesoft.com - mule_server: This is the URL or IP address of the server where a Mule Runtime with the Mule Agent is running. The MULE_SERVER host definition is utilized by the ARM APIs. For example, the value might be http://localhost:9999. - auth_provider: This is the OAuth Provider URL responsible for obtaining a Bearer token used for making requests to all the APIs. By default, it is preconfigured with https://anypoint.mulesoft.com/accounts/api/v2/oauth2/token. However, please note that it might differ for EU or GOV Mule Regions. For specific configurations in these regions, refer to the documentation at link to documentation, see https://docs.mulesoft.com/access-management/managing-users#prerequisites - username: The user name for the authentication API - aws_secret_name: The AWS Secret Manager Name where the password for the authentication API is stored. - env_id: The Environment ID for environment-specific requests - org_id: The Organization ID for the requests that require to specify it - api_key:The API key provided when you purchased the product - customer_key: The Customer key provided when you purchased the product - connection_wait_time: The number of seconds that authentication method will wait until the next retry. If not specified it defaults to 2 - connection_attempts_num: The number of retry attempts that the authentication method will perform. If not specified it defaults to 3 - In the Full Example section, there is an example of a configuration file with all the values configured. instances This section contains a list of instances defined following the YAML list item notation -. Each instance is scheduled independently to run a set of APIs with a specific threads number configuration. Each instance contains the following configurations: - min_collection_interval: The time in seconds between executions. If not specified it defaults to 15 seconds - threads: The number of allowed parallel threads running the instance - api_filter: If not specified, all the APIs are executed, otherwise it must contain a list of APIs to run within the instance following the YAML list item notation In the Full Example section, there is an example of a configuration file with a list of instances. The example is taken directly from the conf.yml file distributed with the integration and contains the optimum numbers we recommend for almost any scenario for min_collection_interval and threads. The metric collection of any instance can be disabled at any time by commenting out the whole instance. This means, commenting on the two attributes mentioned above. Configuration process The instances section contains a list of instances that were set to a periodicity and concurrency level according to each API-provided information. Even if all these values can be changed, we recommend just go with the defaults. The main configuration parameters to pay attention to are: - object_store_v2. - mule_server - username - aws_secret_name. - env_id. - org_id. - api_key - customer_key. For EU or GOV Mule Regions, the anypointand oauth_provider should be changed too. See https://docs.mulesoft.com/access-management/managing- users#prerequisites Configuration | The Service>",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,cloudwatch",high
How do I configure CLOUDWATCH MULE INTEGRATION - Customization | General?,"CLOUDWATCH MULE INTEGRATION - Customization | General General This section contains only general information on the configuration settings. - Customer Key: This is the activation key of the product. Itâs granted by NOVA when purchasing the product and activating it for the first time. Anypoint Information This section contains information about the Anypoint Platform. - User name : The user created in Anypoint Platform with privileges to collect metrics from the different products. - AWS Secret Name : The name of the key created at deployment time where the userâs password is securely stored in AWS Secrets Manager. - Organization Id : The Id of the Anypoint Organization. To know this value, read the official MuleSoft documentation https://docs.mulesoft.com/access-management/organization#manage-master-organization-settings - Environment Id : The Id of the target environment in Anypoint. To know this value, read this official article from MuleSoft https://help.mulesoft.com/s/article/How-to-get-the-Environment-ID - Anypoint URL : The Anypoint server host URL. It is preconfigured with https://anypoint.mulesoft.com but it could be different for EU or GOV Mule Regions, see https://docs.mulesoft.com/access-management/managing-users#prerequisites. - Object Store V2 URL : The Specific Region Object Store V2 server host URL. See https://docs.mulesoft.com/object-store/osv2-apis for the full list of available hosts. This host definition is used by the Object Store API. Example value: https://object-store-us-east-1.anypoint.mulesoft.com. - Object Store stats URL : The Object Store V2 Stats server host URL. This host definition is used by the Object Store V2 Stats API. It is preconfigured with https://object-store-stats.anypoint.mulesoft.com. - OAuth v2 URL : The OAuth v2 Provider URL allows obtaining a Bearer token used to make requests to all the APIs. It is preconfigured with https://anypoint.mulesoft.com/accounts/api/v2/oauth2/token but it could be different for EU or GOV Mule Regions, see https://docs.mulesoft.com/access-management/managing-users#prerequisites - Basic Auth URL : The URL to do basic authentication to make requests to all the APIs. It is preconfigured with https://anypoint.mulesoft.com/accounts/login but it could be different for EU or GOV Mule Regions, see https://docs.mulesoft.com/access-management/managing-users#prerequisites - On-prem Mule Server URL : The URL or IP of the Server running a Mule Runtime with the Mule Agent. This host definition is used by the ARM APIs Example value: http://localhost:9999 MuleSoft Products This section covers what are the MuleSoft products from which the CloudWatch Mule Integration agent will collect metrics. - API filter : This is the MuleSoft product that will be enabled. Pick one from the drop-down list. - Number of threads : This shows an explanation below the control. Specifies the number of threads used to collect metrics from this specific product. Use this setting to tune the performance of the metrics collection. - Frequency (seconds) : The frequency at which this agent will trigger the metric collection for this MuleSoft product. It is specified in seconds. To add more products to the list of managed products for this CloudWatch Mule Integration agent, click on the Add button at the bottom of the section. To remove a product from the list of managed products, click on the Remove button. Advanced Settings This section contains settings that will be updated only under specific circumstances. - Connection wait timeout (s) : The number of seconds that the authentication method will wait until the next retry. If not specified it defaults to 2 seconds. - Connection attempts : The number of retry attempts that the authentication method will perform. If not specified it defaults to 3 attempts. - Proxy user : The user name of the proxy if the instance where the CloudWatch Mule Integration agent is deployed is behind a secured proxy. - Proxy password : The password of the user of the proxy if the instance where the CloudWatch Mule Integration agent is deployed is behind a secured proxy. - Proxy HTTP URL: The IP address or hostname of the proxy server. This control is used if the proxy is used for HTTP only. - Proxy HTTPS URL: The IP address or hostname of the proxy server. This control is used if the proxy is used for HTTPS only. - No proxy domains : The domains that are not required to go through a proxy. It skips the proxy routing. Troubleshooting The web application is not running To diagnose that the application is not running, you need to SSH into the EC2 instance where it is supposed to be running. In the command line, use the following command to make sure the process is not running. ```yaml $ ps -ef | grep ""com.ioconnectservices.cmi.web.CmiSettingsWebAppApplication"" ``` If the command above does not return a valid process, then it might be down. Use the following command to start it. ```yaml $ sudo -u cmi-agent java -Dconf.file.location=""/home/cmi-agent/iocs/conf/conf.yml"" -jar ""/home/cmi-agent/iocs/cmi/cmi-settings-web-app-1.0.0.jar"" ""com.ioconnectservices.cmi.web.CmiSettingsWebAppApplication"" ``` To test the process open a web browser and go to the settings web application http://:8080/settings The web application is not storing any new settings Make sure that the user that runs the web application process has write permissions over the conf.yaml file. By default, both file and Java processes are run with the cmi-user user.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,cloudwatch,troubleshooting",high
How do I configure CloudWatch Mule Integration - Customization?,"CloudWatch Mule Integration - Customization Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. The instances property in conf.yml enables customization of metric collection by the agent, allowing for manual load balancing across different instances. This feature lets you tailor data gathering for CloudHub and On-Prem apps, focusing on specific metrics like CPU, memory, and networking at desired rates without overloading the agent. For example, to monitor these metrics through the ""Development: Optimizations"" dashboards without taxing the agent on resource allocation metrics, you can adjust the configuration accordingly to meet your monitoring needs. yaml instances: - min_collection_interval: 172800 threads: 32 api_filter: - access_management - min_collection_interval: 10 threads: 32 api_filter: - cloudhub With the above example, you are running two isolated executions of our metric reader program, if you have a scenario where customization of API calls is needed you can refer to the configuration section to locate the configuration YAML file and set your configuration properly. Once done, you only need to restart the agent to load the new configuration and that's it you will now have a customized agent. Customize the settings with the UI The CloudWatch Mule Integration comes with a bundled web application to assist in the customization of the settings in a graphical user interface, rather than modifying the configuration YAML file directly. System architecture Bundled with the CloudWatch Mule Integration, the web application follows the same system architecture. The web application uses a plain HTTP connection, meaning it is not encrypted and the information travels in plain text. It's very important to access this web application in a trusted network, typically, with a VPN. The web application listens to port 8080, and the URL to access it is http://:8080/settings Where is the IP address or hostname of the EC2 instance where the CloudWatch Mule Integration is running. Installation This web application comes bundled with the CloudWatch Mule Integration. Follow steps in NOVA/cmi/installation Customization This web application is a user interface for the conf.yaml file used by the CloudWatch Mule Integration agent to configure the execution and collection of metrics. See the definition of each field in the configuration. The UI is divided into sections: - General - Anypoint Information - MuleSoft Products - Advanced settings Make sure you save all changes by clicking on the Save button at the bottom of the page. Once the changes are saved, restart the agent. NOTE: Make sure to restart the agent in the command line. Otherwise, the changes won't take effect.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,cloudwatch,dashboard",high
How do I configure CLOUDWATCH MULE INTEGRATION - Installation?,"CLOUDWATCH MULE INTEGRATION - Installation The CloudWatch Mule Integration is obtained when you subscribe to the AWS CloudWatch Mulesoft Integration. This will deliver an AMI and a CloudFormation template with all the new to Monitoring Anypoint Metrics into AWS CloudWatch The AMI contains Ubuntu Server 20.04 LTS Java 11 Stable. CMI Assets CMI daemon script CMI Agent JSVC cmi-agent-role (Role with custom policy) Settings Web App Installation process 1. Subscribe to theAWS Marketplace* - *Go to this linkMarketplace link and login with your credentials, Search for the *AWS CloudWatch Mulesoft Integration*and subscribe. 2. CloudFormation Template - Once subscribe you will receive a cloudFormation template. In this template, the resources created are an EC2 instance and a security group. This template requires the user to provide the following parameters: - Authentication API - Username - Password - Environment ID - Organization ID - Customer Key - EC2 Configuration - Instance Type - Key Pair - VPC ID - Subnet ID - CIDR IP Range for SSH - CIDR IP Range for Web App - Deployment Environment - Deployment Environment (dev, qa, prod, etc)",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,cloudwatch,monitoring",high
What do I need to know about CLOUDWATCH MULE INTEGRATION - OOTB Assets | Operations?,"CLOUDWATCH MULE INTEGRATION - OOTB Assets | Operations Those widgets work by selecting the time range and the right variables located at the top: _Pro-tip : _Configure the MuleSoft organization and environment identifiers and save the view. Operations: Infrastructure The dashboard has two sections: SECTION CLOUDHOUB: Shows resource usage by application: - Memory used - Memory percentage - CPU usage - CPU percentage - Network in and out - Message queue and Inflight SECTION ON-PREMISE: Shows resource usage by target and machine: - Memory used - Memory percentage (base 256 MB) - CPU used - Network in and out COMMON SECTION: - Applications stopped It works similar to the dashboard mentioned before, you must select the variables values and time range as needed: Operations: Resources allocation and usage This dashboard presents the resources available and used of your infrastructure per main organization. The dashboard is divided into six sections: SECTION 1. ORGANIZATION VCORES: It displays the VCores assigned and reassigned per organization, also has a subsection that shows: - vCores used by environments - vCores reassigned per suborganization - VPNs usage - VPCs usage - Load Balancers usage - Static IPs usage SECTION 2. RESOURCES USAGE The next sections include a table that contains resource allocation by organization name, resources reassigned and assigned. - Organization VPNs - Organization VPCs - Organization Load Balancers - Organization Static IPs SECTION 3. RESOURCE RE-ALLOCATION Resources from Anypoint Platform in an organization can be reassigned to a sub-organization. The next collapsible sections show how these resources are reassigned to sub-organizations. Operations: APIs Total Requests Total Request Size Total Response Size Average Response Total Failed Requests 1xx & 3xx Total Failed Requests 4xx Total Failed Requests 5xx Development: Optimizations The dashboard displays basic information about CloudHub applications and On- Premise servers. It is divided into CloudHub and On-Premise sections that shows: - CPU used - Memory used - Network in and out",datadog-mulesoft-docs,"datadog,mulesoft,documentation,integration,cloudwatch,dashboard",high
What do I need to know about CLOUDWATCH MULE INTEGRATION - OOTB Assets?,"CLOUDWATCH MULE INTEGRATION - OOTB Assets Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. CloudWatch Mule Integration offers seven dashboards and thirteen monitors for comprehensive visualization and management of your infrastructure resources. Metrics collected serve as the basis for the insights provided by these tools. After installing the CloudWatch Mule Integration, access to all dashboards and monitors becomes available on the CloudWatch page. DASHBOARDS: - Development: Optimizations. - Execs: Cost optimization. - Operations: APIs - Operations: Infrastructure. - Operations: Resources allocation and usage. MONITORS: - CloudHub and On-Premise. - Applications stopped. - CPU Load. - Memory usage. - On-Premise. - Servers stopped. - Application errors. - CloudHub. - Queue overload. Prerequisites Before using the dashboards, you must know the identifiers of the organization and environments. This will help to filter out the graphics in the dashboards as well as properly use the tags in the metrics. MuleSoft has documented this in the following articles: How to know my Organization ID (Org ID) on the Anypoint Platform https://help.mulesoft.com/s/article/How-to-know-my-Organization-ID-Org-ID-on- the-Anypoint-Platform How to get Anypoint platform organization details via Anypoint APIs https://help.mulesoft.com/s/article/How-to-get-Anypoint-platform- organization-details-via-Anypoint-APIs It's advisable to save custom views in dashboards requiring these identifiers for optimal visualization. Dashboards Find the assets on the CloudWatch Dashboards section: The Dashboard List should be like this one: Letâs review how they work. Execs: Cost Optimization This dashboard monitors the resources available and not available through time per organization, helping you to identify how are being used easily. The first section Application and Server failures shows critical and sensitive information about all the infrastructure: - Applications stopped time. - Applications stopped TOP 10 list. - Applications error On-Premise. - Applications errors On-Premise TOP 10 list. The next section presents the usage of the following resources: - vCores. - VPNs. - VPCs. - Static IPs. - Load Balancers. - Premium Connectors. - Object Store. The information is displayed as values with its own timeline graphic, showing the values through time: Those widgets work by selecting the time range and the right variables located at the top: Pro-tip : Configure the MuleSoft organization and environment identifiers and save the view.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,connector,cloudwatch,dashboard",high
How do I configure CLOUDWATCH MULE INTEGRATION - System Architecture?,"CLOUDWATCH MULE INTEGRATION - System Architecture Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. The CloudWatch Mule Integration is an agent-based integration. Pre-requisites NOVA API The CloudWatch Mule Integration does a license check via SSL and hence it requires outbound access to: - https://api.ioconnectservices.com/ - *Port: 443* On-prem Mule servers On-prem Mule servers must be registered in Anypoint Runtime Manager (ARM) to be able to collect data. The RM Agent comes in the /bin folder of the Mule runtime, then you can perform the command in CLI. See instructions in https://docs.mulesoft.com/runtime-manager/servers- create. Any server thatâs registered in a group or cluster in ARM must be able to gather metrics from those as well. Mule Networking pre-requisites In order for the agent to properly connect to ARM in Anypoint, specific network configuration must be allowed. All DNS names, ports and IPs needed to hook the agent are documented in https://docs.mulesoft.com/runtime- manager/rtm-agent-whitelists. CloudHub applications Given the cloud nature of applications deployed to CloudHub, all application and server metadata is intrinsically stored by default on Anypoint Control Plane. No special configuration is required other than the needed permissions in the connected app. Ports and Hostnames to whitelist The CloudWatch Mule Integration must have an internet connection on port 443 for outbound connections at least. In enterprises, itâs very common that all networks are behind a firewall to protect access. In many other cases, reverse proxies are used to protect outbound communications to restricted websites. Customers must configure rules in the firewall and proxies to ensure the communication to all NOVA Services, Anypoint and CloudWatch. NOVA networking requirements This is an outbound communication only and itâs initiated by the CloudWatch agent running on-premise. MuleSoft Anypoint networking requirements Communication from Mule servers, installed on-prem, must allow inbound and outbound connections to the following DNS names via port 443 (HTTPS) and 9999 (configurable websocket). Here is a full list of the FQDNs that need to be whitelisted. Pick the ones corresponding to the region to which you MuleSoft organization belongs to. - anypoint.mulesoft.com - eu1.anypoint.mulesoft.com - mule-manager.anypoint.mulesoft.com - mule-manager.eu1.anypoint.mulesoft.com - runtime-manager.anypoint.mulesoft.com - runtime-manager.eu1.anypoint.mulesoft.com - arm-auth-proxy.prod.cloudhub.io - arm-auth-proxy.prod-eu.msap.io - data-authenticator.anypoint.mulesoft.com - data-authenticator.eu1.anypoint.mulesoft.com - analytics-ingest.anypoint.mulesoft.com - analytics-ingest.eu1.anypoint.mulesoft.com - exchange2-asset-manager-kprod.s3.amazonaws.com - exchange2-asset-manager-kprod-eu.s3.eu-central-1.amazonaws.com Learn more about the MuleSoft Anypoint networking requisites in https://docs.mulesoft.com/runtime-manager/rtm-agent-whitelists CloudWatch networking requirements Communication from the CloudWatch agent is via port 443 (HTTPS). < OOTB Operations",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,cloudwatch,architecture",high
What is Datadog Mule Integration and how does it work?,Datadog Mule Integration Overview Datadog Mule Integration is an agent-based integration that collects metrics from MuleSoft products and uploads them onto Datadog. In the Datadog Mule Integration bundle you will find: 150+ metrics 7 out-of-the-box dashboards 13 out-of-the-box monitors Datadog Connector for Mule 4 You can use these metrics to take advantage of the out-of-the-box dashboards and monitors or you can create your own visualizations.,datadog-mulesoft-docs,"datadog,mulesoft,documentation,overview,connector,dashboard",high
What is Datadog Mule Integration 4 APM and how does it work?,"Datadog Mule Integration 4 APM Datadog Integration Datadog Mule Integration 4 APM â¢ Installation Process â¢ APM Connector Configurations â¢ APM Connector Operations â¢ Step by step tracing Sample Introduction to Datadog Mule Integration 4 APM (DMI4APM) Overview The Datadog Mule Integration 4 APM (DMI4APM) enhances the monitoring capabilities of your Mule applications by seamlessly integrating with Datadog's APM system. Our solution extends the functionality of Datadog's APM connector by adding Mule-specific operations that encapsulate application flows. These operations not only capture and send trace data to Datadog APM but also facilitate the propagation of these traces across Mule applications and APIs. Datadog APM Integration Datadog's Application Performance Monitoring (APM) offers real-time insights into the performance of your applications, helping you track requests as they travel across different services and detect issues before they affect your customers. DMI4APM leverages this powerful feature to provide in-depth visibility into the health and performance of Mule applications. Logs DMI4APM ensures that all operational data is captured and logged, allowing for comprehensive traceability. The connector processes these traces, ensuring that the full journey of a request is visible in the Datadog APM interface, from the entry point in a Mule application to external services and back. Mule Application Requirements - APM Mule Connector : Your Mule applications or APIs must have the APM Mule connector installed. This connector is vital for wrapping your application flows and enabling the propagation of trace data to the Datadog APM system. You can find it here. - Application Modifications : You will need to integrate Mule connector operations into your Mule applications or APIs. This step is essential for capturing the performance data that DMI4APM will process and send to Datadog. Software Requirements - Java : Java 21 must be installed on your system, as DMI4APM requires it to run the necessary processes for APM data collection and integration. - Datadog Agent : A functioning Datadog Agent installation is required to facilitate the collection and forwarding of metrics and traces to the Datadog platform. System and Network Requirements - Operating System : DMI4APM is compatible with both Linux and Windows operating systems, allowing you to choose the environment that best fits your infrastructure. - TCP Port : Ensure that TCP port 8127 is available and not being used by any other processes. DMI4APM uses this port to receive APM trace data, so it is crucial that this port is free to avoid any conflicts. Important Notes - Verify that your system meets these requirements before proceeding with the installation. - Additional dependencies or configurations may be required depending on your specific system setup or the complexity of your Mule applications. By meeting the above requirements, you can ensure that DMI4APM will function correctly within your Mule environment, providing you with comprehensive monitoring and improved performance insights. System architecture Installation Guide for DMI4APM from the Datadog Marketplace Before beginning the installation process for the Datadog Mule Integration 4 APM (DMI4APM), ensure that you have a Datadog account and that the Datadog Agent is installed and running on your system. The installation process outlined below is necessary to enable DMI4APM within your infrastructure, allowing you to start monitoring your Mule applications with Datadog's advanced APM capabilities. Prerequisites Datadog Account: Ensure you have an active Datadog account. If you do not have an account, you can sign up at the Datadog website. Datadog Agent: The Datadog Agent must be installed and functioning on your system. For installation instructions, refer to the official Datadog Agent documentation. System Compatibility: Verify that your system meets all the necessary requirements as described in the previous sections, including software, system, and network requirements. Connected App: DMI4APM requires an Anypoint Platform connected app to validate there is an active Mule license. At the level of the Anypoint Platform master organization, create a connected app as ""App acts on its own behalf - client credentials"" and assign the ""View Organization"" permission. Installation Steps Once you have met all the prerequisites, follow these steps to install DMI4APM from the Datadog Marketplace: Note: This steps must be executed as a standard user. Use root privileges only with specific sudo commands. Open a Terminal or Command Prompt: Access your terminal or command prompt on the system where the Datadog Agent is installed. Run the Installation Command: Enter and execute the following command to install the DMI4APM integration: sudo -u dd-agent datadog-agent integration install --third-party datadog-iocs- dmi4apm==X.Y.Z This command installs the DMI4APM version X.Y.Z as a third-party integration within your Datadog Agent environment. Next Steps After successfully installing DMI4APM, proceed with the configuration guide to set up and customize DMI4APM according to your monitoring needs. This includes setting up initial configuration settings, instances, and key configuration elements as detailed in the previous sections. By following these steps and ensuring your system meets all requirements, you can leverage DMI4APM for comprehensive monitoring and improved performance insights within your Mule environment. Configuration Guide for Datadog Mule Integration 4 APM (DMI4APM) DMI4APM requires specific configuration settings to ensure successful integration with the Datadog platform and the Mule applications. Below is a guide to help you configure DMI4APM with the initial settings necessary for the Datadog integration. Configuration Settings Begin by setting the initial configuration for your integration with Datadog. This involves specifying the client_id and client_secret provided by Mule, as well as the dd_api_key , which is your unique Datadog API key. These configuration settings will be provided in the conf.yaml file, which can be found in at /etc/datadog-agent/conf.d/iocs_dmi4apm.d/ Initial configuration settings for the Datadog integration init_config: client_id: """" client_secret: """" dd_api_key: """" Replace < YOUR_MULE_CLIENT_ID>, < YOUR_MULE_CLIENT_SECRET>, and < YOUR_DATADOG_API_KEY> with the credentials provided to you by Mule and Datadog. Next, configure the instances and set the parameters for collection intervals, buffer sizes, tracer ports, and server ports. Here is an example configuration: instances: - min_collection_interval: 15 tracer: source: port: 8127 destination: port: 8126 vm_options: - ""-Xmx128m"" Key Configuration Elements - min_collection_interval : The minimum interval between data collections, in seconds. - tracer : - source.port : The port where DMI4APM listens for incoming trace data (8127 by default",datadog-mulesoft-docs,"datadog,mulesoft,documentation,overview,apm,connector",high
"How do I configure < YOUR_MULE_CLIENT_ID>, < YOUR_MULE_CLIENT_SECRET>, and <?","< YOUR_MULE_CLIENT_ID>, < YOUR_MULE_CLIENT_SECRET>, and < YOUR_DATADOG_API_KEY> with the credentials provided to you by Mule and Datadog. Next, configure the instances and set the parameters for collection intervals, buffer sizes, tracer ports, and server ports. Here is an example configuration: instances: - min_collection_interval: 15 tracer: source: port: 8127 destination: port: 8126 vm_options: - ""-Xmx128m"" Key Configuration Elements - min_collection_interval : The minimum interval between data collections, in seconds. - tracer : - source.port : The port where DMI4APM listens for incoming trace data (8127 by default). - destination.port : The port to which DMI4APM forwards the trace data (8126 by default). - vm_options : JVM options for running DMI4APM, such as memory limits. Applying the Configuration To apply these settings, insert them into the appropriate configuration file for DMI4APM, typically named conf.yaml or similar this has to be save in the following folder. Linux: /etc/datadog-agent/conf.d/iocs_dmi4apm.d Windows: C:\ProgramData\Datadog\conf.d\iocs_dmi4apm.d After updating the configuration file with your specific values, restart DMI4APM to apply the changes. - Always keep your client_id , client_secret , and dd_api_key secure and do not share them publicly. - Adjust the buffer size and time limit settings based on the volume of your trace data and network conditions. - The VM options should be set according to the available system resources and the needs of your application. By following this guide and correctly applying the configuration settings, you will establish a robust connection between your Mule applications and Datadog's monitoring services. Verification: After the installation completes, verify that DMI4APM has been installed successfully by checking the Datadog Agent's status. You can do this by running: sudo -u dd-agent datadog-agent status Look for datadog-iocs-dmi4apm in the list of installed integrations to confirm that the installation was successful. To confirm if the DMI4APM integration is running, follow these steps: Navigate to the log directory by using the following path: /var/log/datadog Display the content of the apm.log file. Check the log output for the following message to verify that the integration is running:",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,apm,monitoring",high
How do I configure Datadog Mule Integration 4 APM?,"Datadog Mule Integration 4 APM Global Elements Datadog Mule Integration 4 APM â¢ Installation Process â¢ APM Connector Configurations â¢ APM Connector Operations â¢ Step by step tracing Sample Datadog APM Config The Datadog APM Config is the global configuration of the Connector. It establishes the connection between the Mule application and the Datadog agent running APM. These are the connection settings, here you set the host where the Datadog Agent is running, and the port. These are optional information to give more context about the connection, by default the service name is unnamed-java-app , even if this field is empty. Version: This allows you to specify the version of your app, which will be visible in the Datadog platform.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,apm,connector",high
How do I configure Datadog Mule Integration 4 APM?,"Datadog Mule Integration 4 APM Log4j Datadog Mule Integration 4 APM â¢ Installation Process â¢ APM Connector Configurations â¢ APM Connector Operations â¢ Step by step tracing Sample To use this operation, you need to configure the appended in the log4j2.xml file in your project as the below example. This will help to forward the logs captured in Log4J2 to the Datadog Log platform. Note that there's a system variable, ddApiKey , that is passed at runtime. Tag Version: When you set the version property in your application, a version tag is added to all your traces. This helps correlate apps and identify errors. The global configuration now includes a ""version "" property. This allows you to specify the version of your app, which will be visible in the Datadog platform. ```yaml ``` In Studio, you can configure this variable as a VM argument. Logs forwarding in CloudHub Configure the log4j2.xml file with the CloudHub appender. ```yaml <PatternLayout pattern=""[%d{MM-dd HH:mm:ss}] %-5p %c{1} [%t]: %m%n""/> ``` When an application is deployed in CloudHub the Runtime Manager always overwrites the log4j2.xml Disable the CloudHub logs in order for Runtime Manager to apply the projectâs log4j2.xml configuration file. By default, Disable CloudHub logs is not a visible option in Runtime Manager. A special request to the Mulesoft support team is required to enable this option. More info: https://docs.mulesoft.com/runtime-manager/custom-log- appender In order to deploy the app in CloudHub, add the ddkeyApi property. Because of security reasons, put in the mule-artifact.json ddApiKey as a secure property: ```yaml { ""minMuleVersion"": ""4.3.0"", ""secureProperties"": [""ddApiKey""] } ``` The logs shown in the live console are the logs generated by the log4j2.xml file. The same event Id can be seen in the log forwarded to Datadog Log.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,apm,connector",high
How do I configure Datadog Mule Integration 4 APM?,Datadog Mule Integration 4 APM Run Configurations Datadog Mule Integration 4 APM â¢ Installation Process â¢ APM Connector Configurations â¢ APM Connector Operations â¢ Step by step tracing Sample,datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,apm,connector",high
How do I configure Datadog Mule Integration 4 APM?,"Datadog Mule Integration 4 APM Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. Operations Datadog Mule Integration 4 APM â¢ Installation Process â¢ APM Connector Configurations â¢ APM Connector Operations â¢ Step by step tracing Sample Create Span The create span operation as states, creates a new span in the flow, it will run in the flow until it gets finished. A span can contain Children, and those Children as well can contain Children and so on, this is useful to add granularity to the project. The operation looks like this: - Display name: By default is displayed as Create Span. - Connector configuration: This is where the Datadog Global Configuration is set, required. - Span name: required. - Parent: The parent of the created span, optional. - Finish this span at the end of the main flow: This checkbox ensures that the span will be closed automatically at the end of the flow execution, the default is unchecked. - Tags: These* are key-value pairs that can be set *Inline or with DataWeave expressions , this provides labels attached to the spans that are created in execution time, optional. - HTTP Request Tags: Additional info the user can provide to the span, in this case the HTTP Method and the URI Path in case the user may require it for REST Services. Accept DataWeave expressions as well as static values. optional. The following is an example of how to assign a child span to a parent. This flow will be used as the main example thoughout the different operation explanations. Letâs check how this can be useful. There are 3 spans created in the flow: Parent, Child, and GrandChild The main span is called Parent , then in the Child span we assign the Parent field as Parent , which is the name of the first span created, and finally, we assign GrandChild span Parent field as Child. With this we have the following hierarchy: Parent will contain Child , at the same timeChild will containGrandChild. If we run the following flow and go to the Datadog APM, the result is this trace: And here the spans created: As you can see, Child and GrandChild are nested to the Parent. Nesting can have n level. The Create Span element sets a Span with a name, this span will run as soon as is created in the flow, can have a parent and fields for tags. ```yaml ``` Distributed tracing Context Injection None: No injection information. Edit Inline: Define properties for trace information. ```yaml Trace ID: (Required) to specify the trace ID of the propagated trace to correlate the trace to be created Parent ID: (Required) to specify what ID is our parent, we need the parent ID to successfully create the context of the trace to create. Sampling Priority: Used for sampling rules by priority contains a numeric value Baggage Items: The Baggage items are the tags propagated from other traces to your trace to create. This is a Map of string, string, representing the key and value to get the baggage items. A common example of a propagated tag could be orderId or customerId. ``` Note: Ensure baggage item values are not null. Use DataWeave expressions with â#[]â for transformations. Context Propagation The context propagation section is where you will set the tags you want to distribute. All the tags defined here will be shown in Datadog platforms as normal tags but also will get in the Create Operation response with the next format âot-baggage-TAG-NAMEâ, and you can use it to propagate to your other apps. When you set baggage items you can define it as next. The baggage items in context propagations is a Map of string, string, representing the key and value. A common example of a propagated tag could be the correlationId or customerId. Note : If you set a property to define a baggage item you need to ensure that the value is not null. DataWeave expressions are not set by default, you need to define the â#[]â before using a DataWeave transformation. Parameters Name | Type | Description | Default Value | Required ---|---|---|---|--- config-ref | Configuration | Global configuration element of the operation | | x spanName | String | Name of the span to be created | | x parent | String | Name of a span that will act as the parent of the one created in this operation | | method | String | HTTP Method to be inserted in the span | | path | String | Path to be inserted in the span | | tags | Map | Key-value pair of tags that can be inserted in the span | | autofinish | Checkbox | Indicates if span will be auto finish at the end of the flow | false | Trace ID | String | Trace ID for context propagation | | x Parent ID | String | Parent ID for the next trace | | x Sampling priority | Int | Used for sampling rules and rates | | Baggage items | Map | Tags distributed through all spans | | Baggage items | Map | Tags distributed through all spans for context propagation | | Output âCreate Spanâ Operation now returns a HashMap Object In APM Connector versions < 3.0.0 the Create operation returns a void element, but this changed with this update. Now we return a HashMap object of a key, value pair representing the span context of the created object. The objective of this have the ability to distribute the span to different applications. This means we will be able to propagate our trace updates in our apps. When you use the Create operation you will get the next parameters. They are the same fields that you get with the create operation: - x-datadog-trace-id : this field has the trace id. You will use this trace ID to propagate the context to other apps and correlate the next trace to be created - x-datadog-parent-id : You can use this field to specify the parent of the next traces. - x-datadog-sampling-priority : This property is used when you are using sampling rules and rates. - ot-baggage -â¦: All elements starting with âot-baggage-â are tags that will be distributed through all our spans. Note : Since the Update operation now returns an object, the payload will be overridden. Store the result value in a target variable. See the ""Recommendations Using the APM Connector 3.0.0"" article. Finish Span The Finish Span element finishes a span already created in the flow, sending this span to the Datadog APM view with its respective timestamps, contains the global configuration and the span name to be finished. ```yaml ``` Name | Type | Description | Default Value | Required ---|---|---|---|",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,apm,connector",high
How do I configure - ot-baggage -â¦: All elements starting with âot-baggage-â are tags that will be distributed through all our spans.?,"- ot-baggage -â¦: All elements starting with âot-baggage-â are tags that will be distributed through all our spans. Note : Since the Update operation now returns an object, the payload will be overridden. Store the result value in a target variable. See the ""Recommendations Using the APM Connector 3.0.0"" article. Finish Span The Finish Span element finishes a span already created in the flow, sending this span to the Datadog APM view with its respective timestamps, contains the global configuration and the span name to be finished. ```yaml ``` Name | Type | Description | Default Value | Required ---|---|---|---|--- config-ref | Configuration | Global configuration element of te operation | | x spanName | String | Name of the span to be finished | | x error | Boolean | Check if the span is marked as error | false | statusCode | Integer | Set the status code of a span if stated | | Update Span The Update Span element updates a span already created in the flow, adding tags to add more optional information between the creation and closure of it. ```yaml ``` Name | Type | Description | Default Value | Required ---|---|---|---|--- config-ref | Configuration | Global configuration element of the operation | | x spanName | String | Name of the span to be updated | | x âUpdate Spanâ Operation now returns a HashMap Object In APM Connector versions < 3.0.0 the Update operation returns a void element, but this changed with this update. Now we return a HashMap object of a key, value pair representing the span context of the created object. The objective of this have the ability to distribute the span to different applications. This means we will be able to propagate our trace updates in our apps. When you use the Update operation you will get the next parameters. They are the same fields that you get with the create operation: Activate Span The Activate Span element sets a span as the new active one, measuring all the current performance in the flow, contains the global configuration and the span name to be activated. ```yaml ``` Name | Type | Description | Default Value | Required ---|---|---|---|--- config-ref | Configuration | Global configuration element of the operation | | x spanName | String | Name of the span to be activated | | x Finish All The Finish All element sets all the spans created to finished at once, this operation is executed based on a LIFO structure, contains the Global configuration ```yaml ``` Name | Type | Description | Default Value | Required ---|---|---|---|--- config-ref | Configuration | Global configuration element of the operation | | x Logger The Logger element creates information to be logged to the stated span in the Span Name field, sending information that can be consulted in the Datadog APM view, contains the Global configuration, the span name, a message, the logging level to be chosen, and the category. This logger operation is designed to help correlating the produced log with the parent trace Id in Datadog APM. ```yaml ``` Name | Type | Description | Default Value | Required ---|---|---|---|--- config-ref | Configuration | Global configuration element of the operation | | x spanName | String | Name of the span in which the logs will be inserted | | x message | String | Message to be inserted in the span | | x level | Enumeration, one of: - DEBUG - ERROR - INFO - TRACE - WARN | Logging level of the log | INFO | | --- | --- | category | String | Label to classify the log | |",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,integration,apm",high
How do I configure Datadog Mule Integration 4 APM?,"Datadog Mule Integration 4 APM Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. How to install Datadog Mule Integration 4 APM â¢ Installation Process â¢ APM Connector Configurations â¢ APM Connector Operations â¢ Step by step tracing Sample Installing a Run the sample tracing applications Sections: Installing and execution Getting the APIs required Exchange configurations Preparing the run configurations Execution of the APIs Getting the APIs required Please download and import in Anypoint Studio each of the 4 APIs jars: - Experience marketing-eapi NOVA/cdn/docs/Datadog-APM-Connector/examples/datadog_apis/marketing-eapi-1.0.0.jar - Process messaging-papi: NOVA/cdn/docs/Datadog-APM-Connector/examples/datadog_apis/messaging-papi-1.0.0.jar - System contacts-sapi: NOVA/cdn/docs/Datadog-APM-Connector/examples/datadog_apis/contacts-sapi-1.0.0.jar - System twilio-sapi: NOVA/cdn/docs/Datadog-APM-Connector/examples/datadog_apis/twilio-sapi-1.0.0.jar Exchange configurations Once all the APIs have been downloaded, we need to set up some Exchange configurations. 1. Ensure you have the Datadog APM Connector publish as an asset in your company's Anypoint Platform Exchange. 2. For each one of the APIs imported, update the pom.xml file by replacing every {ORGANIZATION_ID} with your own Anypoint Platform organization ID. 3. In your local maven installation open your settings.xml file. Add your Anypoint Plataform username and password inside the """" tag. Your server ID in the settings.xml file needs to match exactly with your repository ID in the pom.xml file. You can skip this step if you already have it configured. 4. Anypoint Studio should be able to start downloading the connector from your company's Exchange into your projects. If not happening automatically, please make an update in your pom.xml file or close and reopen each project. Preparing the run configurations Once you have all 4 APIs projects imported, and configurations applied, go to Run > Run configurations... Select all projects to run them simultaneously. In the Arguments tab in the Program arguments box, put the following: ```yaml -Denv=local ``` In the VM Arguments box, put the following (and please replace dd.host and ddApiKey values with your own): ```yaml -Ddd.host={place here your host ip, sample: 127.0.0.1} -DddApiKey={place here your api key sample: abcdefg123456} -Ddomain=localhost -DddAppName1=marketing-eapi-dev -DddAppName2=messaging-papi-dev -DddAppName3=contacts-sapi-dev -DddAppName4=twilio-sapi-dev -DddService1=marketing-eapi-dev -DddService2=messaging-papi-dev -DddService3=contacts-sapi-dev -DddService4=twilio-sapi-dev ``` Execution of the APIs Once installed, use the following curl command to execute the APIs from the Marketing EAPI (please note, calls made by the example APIs shared in this page are just mocked calls). ```yaml curl --location --request POST 'http://localhost:8081/api/messages' \ --header 'Content-Type: application/json' \ --data-raw '{ ""contactId"": ""a0f901f1-9105-4c06-9ec6-82f91a963d9c"", ""body"": ""Demo 10/11 - 001"" }' ``` The Marketing EAPI should return an HTTP status code 201 as a successful response. Now that the transaction has been executed, you should be able to track the event with the correlation ID in your Datadog instance, which is shared across all systems, in the Datadog > Logs section. Take the below image as a reference of what you would be able to find in your Datadog instance.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,apm,connector",high
How do I configure Datadog Mule Integration 4 APM?,"Datadog Mule Integration 4 APM Datadog Config Datadog Mule Integration 4 APM â¢ Installation Process â¢ APM Connector Configurations â¢ APM Connector Operations â¢ Step by step tracing Sample The Datadog APM Global Configuration organizes connection elements such as the host and port, also provides configuration parameters for optional config like the Service Name and the Environment. ```yaml ``` Parameters Name | Type | Description | Default Value | Required ---|---|---|---|--- host | String | Host where the Datadog Instance is running | | x port | int | Port to connect to the Datadog instance | | x service | String | Service name to reference this execution | unnamed-java-app | environment | String | label to states the environment where the execution is running | |",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,apm,connector",high
What is DATADOG MULE INTEGRATION - JMX [On-Prem] | Visualizing and how does it work?,"DATADOG MULE INTEGRATION - JMX [On-Prem] | Visualizing Visualizing the JMX metrics Now, let's confirm you are able to see the metrics in Datadog web page. Login into: https://app.datadoghq.com/account/login?next=%2F Â·Once there, go to the left menu, select Dashboards __ and there, look for JVM Metrics or JVM - Overview dashboard. o If the JVM Metrics dashboard is selected, then go up into the dashboard, below the dashboard name, and check for the $host variable, here select your host or â* â to show hosts gathered metrics. o If the JVM - Overview dashboard is selected, then go up into the dashboard, below the dashboard name, and check for the $scope __ variable, here select your host or â* â to show hosts gathered metrics. o Please find below an image of what it is depicted above: Â·And thatâs it you can visualize your JMX metrics OOB. This link contains the list of the metrics you can obtain from JMX. References",datadog-mulesoft-docs,"datadog,mulesoft,documentation,overview,dashboard",high
How do I configure DATADOG MULE INTEGRATION - JMX [On-Prem]?,"DATADOG MULE INTEGRATION - JMX [On-Prem] The Mule Runtime Manager agent JMX service allows you to monitor specific JMX metrics and send them to external services. The JMX service collects metrics, which are then sent to publishers responsible for transmitting them to external monitoring tools [1]. Datadog offers a monitoring service with a lightweight Java plugin called JMXFetch. This plugin is invoked by the Datadog Agent, connecting to the MBean Server to collect application metrics. It subsequently sends these metrics to the Datadog Agent using the DogStatsD server, which operates within the Agent[2]. Achieving comprehensive monitoring of your Mule runtimes involves installing the Datadog Mule integration into the agent, enabling Datadog APM, and collecting JVM metrics from your Mule runtime. These metrics provide deep infrastructure insights and link your instances/servers with APM services, providing a unified view of your customer-hosted runtime planesâall within a single platform. JMX metrics at mule runtimes To open JMX metrics consumption at your mule servers for the Datadog agent, you must run your mule runtime or add the below arguments [3] to your mule instance conf folder in a file named wrapper-additional.conf: Â·-M-Dcom.sun.management.jmxremote o To allow the JMX client access to the Mule Java VM. Â·-M-Dcom.sun.management.jmxremote.port=portNum o To enable JVM monitoring of your instance. In the property above, portNum is the port number through which you want to enable JMX RMI connections. Â·-M-Dcom.sun.management.jmxremote.local.only=true o If set to false, remote system monitoring can be configured but if you are running the Datadog agent in the same instance where your mule runtime is running this is not neccessary. Â·-M-Dcom.sun.management.jmxremote.authenticate=false o Password authentication for remote monitoring is enabled by default. To disable it, set the following system property when you start the Mule runtime, moreover all traffic is kept locally and no outbound monitoring is configured. Â·-M-Dcom.sun.management.jmxremote.ssl=false o To use client SSL authentication then set it true, N/A for local monitoring. Â·-M-Djava.rmi.server.hostname=host o To enable JVM monitoring of your instance. In the property above, host is the local IP address of your server to enable JMX RMI connections. Note : Above properties, like the host and port, will be used later in the Datadog agent configuration. After running your Mule runtime with the above configuration, the agent can collect these metrics and report them into the Datadog platform, if your Mule runtime was running and you added the properties as a wrapper- additional.conf a restart of your instance is required, letâs configure the agent to do so. Setting up the Datadog Agent for JMX fetch Prerequisites 1. A Datadog agent running. 2. Your Mule applications must be customer hosted. 3. The Datadog agent must be able to communicate with the Mule server. Ensure that the configured host and port for the Mule runtime JMX service are reachable. Configuration/Steps Â·Configure the depicted file at the following link according to your needs and specs, please follow Datadog documentation: o https://docs.datadoghq.com/integrations/java/?tab=host#configuration Â·Restart the datadog agent o Linux: Â§ https://docs.datadoghq.com/agent/guide/agent- commands/?tab=agentv6v7#restart-the- agent o Windows: Â§ https://docs.datadoghq.com/agent/basic_agent_usage/windows/?tab=gui Â·Letâs check the JMXFetch is running and gathering our instance(s): o Please follow the below document to verify that JMXFetch check is executing correctly: Â§ https://docs.datadoghq.com/agent/troubleshooting/agent_check_status/?tab=agentv6v7 Â§ When configured and started successfully, it should show you something similar like the below image:",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,apm,monitoring",high
What is DATADOG MULE INTEGRATION - Configuration | Connected Apps and how does it work?,"DATADOG MULE INTEGRATION - Configuration | Connected Apps The Connected Apps permissions The Datadog Mule Integration relies on specific permissions within the MuleSoft Anypoint Platform to collect metrics. To grant these permissions, a Connected App is used. Follow the instructions in the official MuleSoft documentation to create a Connected App. https://docs.mulesoft.com/access-management/connected-apps- overview The Connected App has to be of the type App acts on its own behalf (client credentials). The Datadog Mule Integration requires the ""View Organization"" permission to collect metrics. Here's a breakdown of the required permissions for different set of metrics: Access Management: READ APPLICATIONS API Events: This permission is solely for reading data from API Manager. Datadog Mule Integration does not modify any modifications. - API GROUP ADMINISTRATOR - VIEW APIS CONFIGURATION - VIEW POLICIES API Manager: API GROUP ADMINISTRATOR VIEW CONTRACTS VIEW POLICIES ARM Monitoring Query: READ APPLICATIONS READ SERVERS ARM Mule Agent: This API needs on premise mule server and configure in conf.yaml. ARM Rest Services READ ALERTS READ APPLICATIONS READ SERVERS CloudHub: This is only required to read data from CloudHub. Datadog Mule Integration does not modify any asset. - CLOUDHUB ORGANIZATION ADMIN - READ ALERTS Exchange Experience API: This is only required to read data from Exchange. Datadog Mule Integration does not modify any asset.__ - EXCHANGE ADMINISTRATOR INSIGHT: CLOUDHUB ORGANIZATION ADMIN Object Store: MANAGE APPLICATION DATA STORES METRICS VIEWER MANAGE STORES DATA VIEW STORE CLIENTS Object Store V2 Stats: This is only required to read data from Object Store V2 statistics.Datadog Mule Integration does not modify any asset.If these metrics are not desired, make sure you comment out this entry in the configuration file in instances . - AN ADMINISTRATOR USER - MANAGE STORES DATA - STORE METRICS VIEWER - VIEW STORE CLIENTS Runtime Fabric: MANAGE RUNTIME FABRICS READ APPLICATIONS The integration does not modify in any manner the assets in Anypoint Platform, those permissions are for read-only. Full example Below is a complete configuration example (with fake credentials and ids): ```yaml init_config: hosts: anypoint: https://anypoint.mulesoft.com object_store_v2: https://object-store-us-east-1.anypoint.mulesoft.com object_store_v2_stats: https://object-store-stats.anypoint.mulesoft.com # mule_server: oauth_provider: https://anypoint.mulesoft.com/accounts/api/v2/oauth2/token basic_auth_provider: https://anypoint.mulesoft.com/accounts/login client_id: 035715123cbc31a123456a43143213f3 client_secret: bAc2345678C34aFF1aB1A12f5A245678 env_id: a3cc1234-4a24-125b-1a45-1c1aa1a13cad org_id: ac2345aa-cc13-1367-bca1-b1234a2aa4aa customer_key: a6a6-b5568ae854e5 connection_wait_time: 2 connection_attempts_num: 3 instances: - min_collection_interval: 86400 threads: 32 api_filter: - access_management - min_collection_interval: 10 threads: 32 api_filter: - arm_monitoring_query - min_collection_interval: 10 threads: 32 api_filter: - arm_mule_agent - min_collection_interval: 10 threads: 32 api_filter: - arm_rest_services - min_collection_interval: 10 threads: 32 api_filter: - cloudhub - min_collection_interval: 60 threads: 32 api_filter: - api_manager - min_collection_interval: 60 threads: 32 api_filter: - api_events - min_collection_interval: 86400 threads: 32 api_filter: - exchange_experience - min_collection_interval: 60 threads: 32 api_filter: - insight - min_collection_interval: 86400 threads: 32 api_filter: - object_store - min_collection_interval: 86400 threads: 32 api_filter: - object_store_v2_stats ``` PREVIOUS TOPIC NEXT TOPIC",datadog-mulesoft-docs,"datadog,mulesoft,documentation,overview,monitoring,configuration",high
What is DATADOG MULE INTEGRATION - Configuration and how does it work?,"DATADOG MULE INTEGRATION - Configuration The Datadog Mule Integration is a Datadog custom integration and it is configured through a conf.yaml file located at: - Windows systems - C:\ProgramData\Datadog\conf.d\iocs_dmi.d\conf.yaml - Linux systems - /etc/datadog-agent/conf.d/iocs_dmi.d/conf.yaml The configuration in the conf.yaml is divided into two parts: - INIT_CONFIG: A common part used by all the executions - INSTANCES : A list of instances to be scheduled independently init_config This section contains the common configuration used by all the instance executions. It contains the following configurations (these should not be removed): - HOSTS :Grouping of all the hosts definitions needed by Mulesoft Anypoint Reader. Some hosts are specific to some APIs, if so, it is specified in the description: - ANYPOINT The Anypoint server host url. It is preconfigured with https://anypoint.mulesoft.com but it could be different for EU or GOV Mule Regions, see https://docs.mulesoft.com/access-management/managing-users#prerequisites OBJECT_STORE_V2 : Object Store V2 server host url. See https://docs.mulesoft.com/object- store/osv2-apis for the full list of available hosts. This host definition is used by the Object Store API. Example value: https://object-store-us-east-1.anypoint.mulesoft.com OBJECT_STORE_V2_STATS : TheObject Store V2 Stats server host url. This host definition is used by the Object Store V2 Stats API. It is preconfigured with https://object-store-stats.aypoint.mulesoft.com MULE_SERVER : This is the URL or IP address of the server where a Mule Runtime with the Mule Agent is running. The MULE_SERVER host definition is utilized by the ARM APIs. For example, the value might be http://localhost:9999. OAUTH_PROVIDER : This is the OAuth Provider URL responsible for obtaining a Bearer token used for making requests to all the APIs. By default, it is preconfigured with https://anypoint.mulesoft.com/accounts/api/v2/oauth2/token. However, please note that it might differ for EU or GOV Mule Regions. For specific configurations in these regions, refer to the documentation at link to documentation. see https://docs.mulesoft.com/access-management/managing- users#prerequisites - CLIENT_ID : The Client ID for the authentication API. This value is obtained by creating a connected app in Anypoint Platform. - CLIENT_SECRET : The Client Secret for the authentication API. This value is obtained by creating a connected app in Anypoint Platform. - ENV_ID : The Environment ID represents the specific environment (such as Development, Staging, or Production). - ORG_ID : The Organization ID for the requests that requires to specify it. - CUSTOMER_KEY : The Customer key is provided from our team once the purchase is completed. - CONNECTION_WAIT_TIME : The number of seconds that authentication method will wait until next retry. If not specified it is defaulted to 2 - CONNECTION_ATTEMPTS_NUM: The number of retry attempts that authentication method will perform. If not specified it is defaulted to 3 In the Full Example section there is an example of a configuration file with all the values configured. instances This section contains a list of instances defined following the YAML list item notation -. Each instance is scheduled independently to run a set of APIs with a specific threads number configuration. Each instance contains the following configurations: - MIN_COLLECTION_INTERVAL : The time in seconds between executions. If not specified it is defaulted to 15 seconds - THREADS :The number of allowed parallel threads running the instance - API_FILTER : If not specified, all the APIs are executed, otherwise it must contain a list of APIs to run within the instance following the YAML list item notation In the Full Example Section there is an example of a configuration file with a list of instances. The example is taken directly from the conf.yaml file distributed with the integration and contains the optimum numbers we recommend for almost any scenario for min_collection_interval and threads. The metric collection of any instance can be disabled at any time by commenting out the whole instance. This means, commenting the two attributes mentioned above. Configuration process The example file provided in datadog_checks/iocs_dmi/data/conf.yaml.example and copied to the conf.d/iocs_dmi.d/conf.yaml.example folder after the installation process contains a configuration with all the possible values already configured and they should just work for the common usage case. instances section contains a list of instances that were set to a periodicity and concurrency level according to each API provided information. Even if all these values can be changed, we recommend just go with the defaults. The main configuration parameters to pay attention are: - OBJECT_STORE_V2 : In the section, it depends on the CloudHub Region and can be found at the following link https://docs.mulesoft.com/object- store/osv2-apis - MULE_SERVER : In the hosts section, it depends on the Mule Agent configuration. Following the defaults of the Mule Agent configuration it would be http://localhost:9999 to retrieve the metrics from a Mule Runtime running on the same machine Connected Apps Authentication The credentials to get access to the Anypoint platform. More information about Connected Apps :https://docs.mulesoft.com/access- management/connected-apps-overview. The two parameters to configure: - CLIENT_ID: Connected Apps account client_id - CLIENT_SECRET: It must be configured with the Connected Apps account client_secret - ENV_ID The Environment ID for environment specific requests. See https://docs.mulesoft.com/access- management/environments and https://help.mulesoft.com/s/question/0D52T00004mXPvSSAW/how-to-find-cloud- hub-environment- id - ORG_ID: The Organization ID for the requests that requires to specify it. See https://docs.mulesoft.com/access- management/organization and https://help.mulesoft.com/s/article/How-to- know-my-Organization-ID-Org-ID-on-the-Anypoint- Platform - API_KEY: The API key provided by NOVA when you purchased the product - CUSTOMER_KEY The Customer key provided by NOVA when you purchased the product For EU or GOV Mule Regions, the anypoint and oauth_provider should be changed too. See https://docs.mulesoft.com/access-management/managing- users#prerequisites",datadog-mulesoft-docs,"datadog,mulesoft,documentation,overview,installation,configuration",high
How do I configure Datadog Mule Integration - Customization?,"Datadog Mule Integration - Customization Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. The instances property in the conf.yaml file allows you to customize how the agent collects metrics. This means you can manually distribute the API requests performed by the agent, balancing the load across different instances and collecting data based on your specific requirements. Let's assume you are interested in getting updated data of your CloudHub and On-Prem apps behavior, through the Development: Optimizations dashboards, you'd like to monitor the CPU, memory and networking in a constant rate, but you won't like to push the agent to get at the same rate the metrics of your resource allocation. You can easily set up the following configuration to fulfill the depicted requirement. yaml instances: - min_collection_interval: 172800 threads: 32 api_filter: - access_management - min_collection_interval: 10 threads: 32 api_filter: - cloudhub In this example, you are running two separate executions of our metric reader program. If you find yourself in a scenario where customizing API calls is necessary, you can refer to the [NOVA/dmi/configuration) section to locate the configuration YAML file and adjust your settings accordingly. After making the changes, simply restart the agent to apply the new configuration, and you will have a customized agent ready to meet your specific needs.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,dashboard,monitoring",high
What is Datadog Mule Integration Installation and how does it work?,"Datadog Mule Integration Installation The Datadog Mule Integration is installed following the standard Datadog integration. This section shows the complete path to follow from the prerequisites to get the integration working. Pre-requisites Make sure you have whitelisted the hosts and ports needed. See the System Architecture section for details. Create a Connected App in Anypoint Access Management with the correct permissions. Java 8. Installation Process To install the iocs_dmi check on your host: Download and install the Datadog Agent from https://app.datadoghq.com/account/settings#agent/overview Run sudo -u dd-agent datadog-agent integration install --third-party datadog-iocs-dmi==X.Y.Z, where ""X.Y.Z"" represents the latest version. Configure the integration with the specific parameters needed to properly gather metrics. Restart (or start) the Agent with administrator privileges following the target platform OS instructions. Verify the installation by running the status command. The iocs_dmi should be listed in the ""Running Checks"" section.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,overview,installation,architecture",high
How do I configure DATADOG MULE INTEGRATION - K8 Kubernetes?,"DATADOG MULE INTEGRATION - K8 Kubernetes Prerequisites: Have a running Kubernetes cluster on AWS (e.g., using Amazon EKS). Ensure that kubectl is installed and configured to interact with your Kubernetes cluster. Make sure you have a Datadog account and access to your API Key and APP Key. [Deploy an Agent with the Operator](https://docs.datadoghq.com/containers/kubernetes/installation/?tab=operator#deploy- an-agent-with-the-operator) 1. Install the [Datadog Operator](https://artifacthub.io/packages/helm/datadog/datadog-operator): - helm repo add datadog https://helm.datadoghq.com - helm install my-datadog-operator datadog/datadog-operator 2. Create a Kubernetes secret with your API and app keys kubectl create secret generic datadog-secret --from-literal api-key= --from-literal app-key= Replace and with your Datadog API and application keys. 3. Create a file. datadog-agent.yaml with the spec of your Datadog Agent deployment configuration. The simplest configuration is as follows: Replace with your Datadog site. Your site is datadoghq.com. (Ensure the correct SITE is selected on the right). ```yaml init_config: global: site: datadoghq.com credentials: apiSecret: secretName: datadog-secret keyName: api-key appSecret: secretName: datadog-secret keyName: app-key override: clusterAgent: image: name: gcr.io/datadoghq/cluster-agent:latest nodeAgent: image: name: gcr.io/datadoghq/agent:latest features: apm: enabled: true hostPortConfig: enabled: true eventCollection: collectKubernetesEvents: true npm: enabled: true logCollection: enabled: true containerCollectAll: true liveProcessCollection: enabled: true externalMetricsServer: enabled: true liveContainerCollection: enabled: true orchestratorExplorer: enabled: true ``` 4. Deploy the Datadog Agent with the above configuration file: kubectl apply -f /path/to/your/datadog-agent.yaml 5. Monitoring Your Kubernetes Cluster in Datadog: Log in to your Datadog account and navigate to the ""Infrastructure"" > ""Host Map"" view. You should see your Kubernetes nodes listed here and be able to view metrics and logs from your cluster. 6. Final Remarks: Remember to customize your Datadog Agent configuration to suit your specific needs, including adding additional integrations, tags, and labels as necessary. You can also enable Datadog's APM and Log Management features to monitor your applications and logs more comprehensively.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,apm,monitoring",high
What do I need to know about DATADOG MULE INTEGRATION - OOTB Assets | Monitors?,"DATADOG MULE INTEGRATION - OOTB Assets | Monitors Monitors Monitors help to constantly keep track of specific events, triggering an alert or notification whenever such events fulfill a condition. Datadog Mule Integration comes with pre built-in monitors for events of failures in the Mule applications or servers. Go to the monitors list by clicking at the side bar: It should be a list like this one: All monitors have the same structure, but each one is configured with specific metrics. The monitor is triggered based on thresholds already set. If you open a monitor in the Edit section, you will find the alert threshold value defined by default. This is different for each monitor: If the alert is triggered, the monitor is going to change to red color, like the image below: You can indicate in the monitor that the issue is fixed by clicking the Resolve button at the top-right corner, the Alert will change the status to OK and the color from red to green: Once updated to âResolveâ, the Alert Monitor widget in the dashboards, also will be updated to OK status. All alerts can be configured to trigger alerts. This is done by configuring the email address, Slack channel or other communication medium that is configured in your Datadog instance. Click on the âEditâ button on the monitor and scroll down to the Notify your team section and configure accordingly. To learn more about monitors go to https://docs.datadoghq.com/monitors/",datadog-mulesoft-docs,"datadog,mulesoft,documentation,integration,dashboard,monitoring",high
What is DATADOG MULE INTEGRATION - OOTB Assets | Operations and how does it work?,"DATADOG MULE INTEGRATION - OOTB Assets | Operations Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. Operations: Resources allocation and usage _Pro tip : _ Configure the MuleSoft organization and environment identifiers and save the view. See how you can obtain the identifiers and save the view in the Datadog dashboard in the prerequisites. This dashboard presents the resources available and used of your infrastructure per main organization. The dashboard is divided into six sections: Section 1. ORGANIZATION vCORES It displays the VCores assigned and reassigned per organization, also has a subsection that shows: - vCores used by environments - vCores reassigned per suborganization - VPNs usage - VPCs usage - Load Balancers usage - Static IPs usage Section 2. RESOURCES USAGE The next sections include a table that contains resource allocation by organization name, resources reassigned and assigned. - Organization VPNs - Organization VPCs - Organization Load Balancers - Organization Static IPs Section 3. RESOURCE RE-ALLOCATION Resources from Anypoint Platform in an organization can be reassigned to a sub-organization. The next collapsible sections show how these resources are reassigned to sub-organizations. Operations: APIs Configure the MuleSoft environment, client application and API instance identifiers and save it. See how you can obtain the identifiers and save the view in the Datadog dashboard in the pre- requisites. The dashboard is divived into 4 sections: Overview Requests summary Failed requests summary Top 10 The overview**** displays a summary of the total of requests, response time and failed requests. Basically it groups the data obtained from the HTTP requests through the Mule event. You can filter out this dashboard by apiId, environment and clientId. Requests summary section contains the gathered data of the HTTP request organized by different aspects of the HTTP protocol, such as verb, request and response size, code, and time. It also shows a summary of the requests identifying the client application. The Failed request summary is much the same as the above section groups the failed request by the metadata of the HTTP protocol. Final section, it's the Top 10's, here a list of the most used APIs, active clients, failed APIs and clients, is displayed. ![Image: Top 10's-1] Along with the sections depicted above, the dashboard shows the health of the Datadog Mule Integration and Datadog Agents. Here a full image of how it looks. Development: Optimizations The dashboard displays basic information about CloudHub applications and On- Premise servers. It is divided into CloudHub and On Premise sections that shows: - CPU used - Memory used - Network in and out For CloudHub section, you can select it by application and environment, for On-Premise section by target and host:",datadog-mulesoft-docs,"datadog,mulesoft,documentation,overview,dashboard,ootb",high
How do I install DATADOG MULE INTEGRATION - OOTB Assets | Cost Optimization?,"DATADOG MULE INTEGRATION - OOTB Assets | Cost Optimization Datadog Mule Integration includes 5 dashboards and 9 monitors to visualize and identify the usage of your infrastructure resources. The data used in the dashboards and monitors is collected by the metrics. Once you finalize the Datadog Mule Integration installation, you will be able to check and use all dashboards and monitors in the Datadog page. DASHBOARDS - Development: Optimizations. - Execs: Cost optimization. - Operations: APIs. - Operations: Infrastructure. - Operations: Resources allocation and usage. - Operations: RTF Infrastructure. - Operations: RTF Resource allocation and usage. MONITORS CloudHub and On-Premise. - Applications stopped. - CPU Load. - Memory usage. On-Premise. - Servers stopped. - Application errors. CloudHub. - Queue overload Runtime Fabric - CPU total usage. - Memory total usage. - App status stopped. - App status pending. Prerequisites Before using the dashboards, you must know the identifiers of the organization and environments. This will help to filter out the graphics in the dashboards as well as properly use the tags in the metrics. MuleSoft has documented this in the following articles: How to know my Organization ID (Org ID) on the Anypoint Platform https://help.mulesoft.com/s/article/How-to-know-my-Organization-ID-Org-ID-on- the-Anypoint-Platform How to get Anypoint platform organization details via Anypoint APIs https://help.mulesoft.com/s/article/How-to-get-Anypoint-platform- organization-details-via-Anypoint-APIs Itâs recommended to save views in the dashboards where these identifiers are needed for proper visualization. Learn more about views here https://docs.datadoghq.com/dashboards/template_variables/#saved-views Dashboards Find the assets in the Datadog web page by clicking at the side bar: ![Image: ootb-assets-1] The Dashboard List should be like this one: Letâs review how they work. Execs: Cost Optimization This dashboard monitors the resources available and not available through time per organization, helping you to identify how are being used easily. The first section Application and Server failures shows critical and sensitive information about all the infrastructure: - Applications stopped time. - Applications stopped TOP 10 list. - Applications error On-Premise. - Applications errors On-Premise TOP 10 list. The next section presents the usage of the following resources: - vCores. - VPNs. - VPCs. - Static IPs. - Load Balancers. - Premium Connectors. - Object Store. The information is displayed as values with its own timeline graphic, showing the values through time: Those widgets work by selecting the time range and the right variables located at the top: _Pro-tip : _ Configure the MuleSoft organization and environment identifiers and save the view. See how you can obtain the identifiers and save the view in the Datadog dashboard in the pre-requisites. By default, the dashboard uses and shows the information of all the organizations and environments (*) in your MuleSoft organization. To bring the information of a specific organization and environment, change the values with the correct Ids and change the time range as needed: Operations: Infrastructure The dashboard is divided in three sections: SECTION 1. CRITICAL : Contains alerts that monitor applications critical behavior: - CloudHub applications stopped - Servers stopped - On-Premise application errors - Queue overload These widgets are connected to the monitors, they show when the monitors are in Alert, OK or No Data status: SECTION 2. CLOUDHUB - Memory used - Memory percentage - CPU usage - CPU percentage - Network in and out - Message queue and Inflight SECTION 3. ON-PREMISE - Memory used - Memory percentage (base 256 MB) - CPU used - Network in and out It works similar to the dashboard mentioned before, you must select the variables values and time range as needed:",datadog-mulesoft-docs,"datadog,mulesoft,documentation,installation,connector,dashboard",high
What is DATADOG MULE INTEGRATION - RTF Operations and how does it work?,"DATADOG MULE INTEGRATION - RTF Operations Operations: RTF Infrastructure This dashboard is divided into three main sections that provides a view of your Runtime fabric applications infrastructureâs health and performance. Section 1. CRITICAL Contains applications with critical status: - Stopped applications: Applications that are not running. - Clusters degraded: Clusters that are experiencing performance issues. - Clusters disconnected: Clusters that are unable to communicate. - Nodes with status not healthy - Nodes with status not ready Section 2. APPLICATION RESOURCES OVERVIEW BY REPLICAS Analyze CPU and memory metrics to ensure efficient resource utilization, to ensure resource utilization. Track storage access, network activity, data read/write operations. _Pro tip : _ Configure the MuleSoft application variable to analyze resource for each replica used by the application variable. Section 3.REPLICAS OVERVIEW This section provides a comprehensive view of your application's replicas, high availability, and resilience. Metrics include: - Total replicas: The total number of replicas currently running. - Replicas in bad phase: Replicas experiencing issues. - Available vs. unavailable replicas: A quick glance at replicas currently serving traffic vs. those that are not. - Desired replicas: The count of replicas you aim to have up and running. - Desired not available: Difference between the desired and actual number of replicas, indicating potential deployment issues. Operations: RTF Resource allocation and usage This dashboard displays the resources consumed by your applications per environment, providing valuable insights into resource utilization. It is divided into three sections: _Pro-tip : _ Configure the MuleSoft environment identifiers (production Environment and sandbox Environment) and save the view. See how you can obtain the identifiers and save the view in the Datadog dashboard in the pre-requisites. Section 1. Environment resources Shows the total cores and memory used by applications in production and sandbox environment. Section 2. Environment details This table categorizes resources by environment: - Usage total reserved CPU. - Usage total CPU limit. - Usage total memory. - Allocated CPU. - Allocated memory. Section 3. Environment application resources Focuses on resources from RTF (Runtime Fabric) applications. - Replicas - Reserved CPU - CPU limit - Memory - Enforced active replicas - Running - Total CPU reserved - Total CPU limit - Total memory",datadog-mulesoft-docs,"datadog,mulesoft,documentation,overview,dashboard",high
What do I need to know about DATADOG MULE INTEGRATION - System Architecture | Ports?,"DATADOG MULE INTEGRATION - System Architecture | Ports Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. Ports and Hostnames to whitelist The Datadog Mule Integration must have internet connection on port 443 for outbound connections at least. In enterprises, itâs very common that all networks are behind a firewall to protect access. In many other cases, reverse proxies are used to protect outbound communications to restricted websites. Customers must configure rules in the firewall and proxies to ensure the communication to all NOVA Services, Anypoint and Datadog. NOVA Networking Requirements The Datadog Mule Integration does a license check via SSL and hence it requires outbound access to: https://api.ioconnectservices.com/ Port: 443 This is an outbound communication only and itâs initiated by the Datadog agent running on-premise. MuleSoft Anypoint Networking Requirements Communication from Mule servers, installed on-prem, must allow inbound and outbound connections to the following DNS names via port 443 (HTTPS) and 9999 (configurable websocket). Here is a full list of the FQDNs that need to be whitelisted. Pick the ones corresponding to the region to which you MuleSoft organization belongs to. - anypoint.mulesoft.com - eu1.anypoint.mulesoft.com - mule-manager.anypoint.mulesoft.com - mule-manager.eu1.anypoint.mulesoft.com - runtime-manager.anypoint.mulesoft.com - runtime-manager.eu1.anypoint.mulesoft.com - arm-auth-proxy.prod.cloudhub.io - arm-auth-proxy.prod-eu.msap.io - data-authenticator.anypoint.mulesoft.com - data-authenticator.eu1.anypoint.mulesoft.com - analytics-ingest.anypoint.mulesoft.com - analytics-ingest.eu1.anypoint.mulesoft.com - exchange2-asset-manager-kprod.s3.amazonaws.com - exchange2-asset-manager-kprod-eu.s3.eu-central-1.amazonaws.com Learn more about the MuleSoft Anypoint networking requisites in https://docs.mulesoft.com/runtime-manager/rtm-agent- whitelists Datadog Networking Requirements Communication from Datadog agent, installed on-prem, must allow outbound connections to *.datadoghq.com via port 443 (HTTPS). Other ports might be used for specific use cases. The FQDNs that need to be whitelisted are: - trace.agent.datadoghq.com: APM - process.datadoghq.com: Live containers - *.agent.datadoghq.com: Log collection - api.datadoghq.com: Non-critical functions such as checking API Key validity Modern firewalls can whitelist request based on OSI's layer 7. Also, you can find these requisites in Datadog site, they are well documented. https://docs.datadoghq.com/agent/guide/network/?tab=agentv6v7 To know the full list of IP ranges that Datadog uses, see the following sites. - https://ip-ranges.datadoghq.com/ - https://ip-ranges.datadoghq.eu/ In Datadog, all communication is outbound, meaning the agent sends data to Datadog and Datadog never requests to client servers. All communication is done through these ports: - 443/TCP: port for most Agent data. (Metrics, APM, Live Processes/Containers) - 123/UDP: Network time protocol (NTP) - 10516/TCP: port for the Log collection over TCP for Datadog US region, 443/tcp for the Datadog EU region. - 10255/TCP: port for the Kubernetes http kubelet - 10250/TCP: port for the Kubernetes https kubelet The only inbound communication needed is to send data to agents within the same network, like it's the case of APM configured in a Mule application using the Datadog APM Connector to trace processes. - 5000/TCP: port for the go_expvar server - 5001/TCP: port on which the IPC api listens - 5002/TCP: port for the Agent browser GUI to be served - 8125/UDP: dogstatsd - 8126/TCP: port for the APM Receiver",datadog-mulesoft-docs,"datadog,mulesoft,documentation,connector,apm,architecture",medium
How do I configure DATADOG MULE INTEGRATION - System Architecture?,"DATADOG MULE INTEGRATION - System Architecture Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. The Datadog Mule Integration is an agent-based integration. This means that the customer must install the agent in a server on-premises and configure it. https://docs.datadoghq.com/developers/integrations/ Prerequisites NOVA API The Datadog Mule Integration does a license check via SSL and hence it requires outbound access to: https://api.ioconnectservices.com/ Port: 443 On-prem Mule servers On-prem Mule servers must be registered in Anypoint Runtime Manager (ARM) to be able to collect data. The RM Agent comes in the /bin folder of the Mule runtime, then you can perform the command in CLI. See instructions in https://docs.mulesoft.com/runtime-manager/servers- create. Any server thatâs registered in a group or cluster in ARM must be able to gather metrics from those as well. Mule Networking pre-requisites In order for the agent to properly connect to ARM in Anypoint, specific network configuration must be allowed. All DNS names, ports and IPs needed to hook the agent are documented in https://docs.mulesoft.com/runtime- manager/rtm-agent-whitelists. CloudHub applications Given the cloud nature of applications deployed to CloudHub, all application and server metadata is intrinsically stored by default on Anypoint Control Plane. No special configuration is required other than the needed permissions in the connected app.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,architecture",high
How do I configure SUPPORT - Troubleshooting?,"SUPPORT - Troubleshooting Guide Title Last Update Created Version DMI appeared to stop reporting metrics in dashboards Feb 17, 2025 APM Connector Compatibility Updating Datadog Integration (DMI4APM) Configuration file on Windows Feb 12, 2025 The following article contains possible errors maybe encounter while Mule Developer is instrumenting a Mule app/api with the APM Mule Connector Jul 17, 2024 Jul 01, 2024 3.0.0 Article contains recommendations related to Taget Variable, Version Property, Baggage items Jun 26, 2024 Article contains recommendations related to send spans to external service for propagation purpose Jul 16, 2024 The api_events.json file contains configuration data related to the metrics and events that the Mulesoft Anypoint Integration fetches. Oct 04, 2023 Sep 22, 2023 1.1.1",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,integration,apm",high
How do I configure SUPPORT - Recommendations Using the APM Connector 3.0.0?,"SUPPORT - Recommendations Using the APM Connector 3.0.0 Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. Last update: July 16, 2024 We have a list of recommendations or good practices when you are using the APM Connector 3.0.0, we highly recommend following them. - Target variable: We recommend always storing the result of a create and update operations in a new variable. Using the connector like that you will avoid problems of overwriting your payload. You can see the next screenshot as an example to define your variable. You can name your variable in the way you wish but we recommend using a name clearly and easily identifiable - Version property in Global config and Log4j2: When you define the version in your global configuration that means that you will add a tag âversionâ in all your traces. But what if you want to add a Log operation to succesfully correlate both traces and logs you need to match the properties of your tags in traces and log configuration, this includes adding a version property. You can follow the example in the Global config new property: âversionâ section, for further details please visit [NOVA/dmi4apm/apm-global-elements) and Log4j section. - Injection of baggage items with DataWeave function: You can use a DataWeave expression to send a variable that resolves in an object of key/value pair. This will help you to get all your properties at once instead define one by one each of your propagated tags. - Propagations of baggage items with DataWeave function: You can use a DataWeave expression to send a variable that resolves in an object of key/value pair. This will help you to send all your properties at once instead set one by one each of your propagated tags.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,apm,connector",high
How do I configure SUPPORT - How to migrate to 3.0.0?,"SUPPORT - How to migrate to 3.0.0 Note: NOVA was formerly known as IO Connect Services. URLs in this document still reference the ioconnectservices.com domain for technical compatibility. Last update: July 17, 2024 We know that you probably come from an older version of APM Connector, if that is your case read the next topics to learn how to migrate to the 3.0.0 version to 3.0.0 When you are migrating from a 2.X.X version to a 3.0.0 you need to follow the next steps to be able to use correctly next versions. - First, you need to update your dependency on the pom.xml file to 3.0.0 version. - Target variable must be stored the result of a create and update operations in a new variable, please review notes below and you can also have further details in the Best Practices article here 1.X.X to 3.0.0 When you are migrating from a 1.X.X version to a 3.0.0 you need to follow the next steps to be able to use correctly next versions - First, you need to update your dependency on the pom.xml file to 3.0.0 version. - The next thing to do is to update your host and port in your global configuration to aim for the correct server. Note: Target variable: the Target variable must be stored the result of a create and update operations in a new variable. Using the connector like that you will avoid problems of overwriting your payload. You can see the next screenshot as an example to define your variable. You can name your variable in the way you wish but we recommend using a name clearly and easily identifiable",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,integration,apm",high
How do I configure SUPPORT - How to Distribute Spans to Other Apps?,"SUPPORT - How to Distribute Spans to Other Apps Last update: July 16, 2024 Send your span context via headers. Here are three methods: As a DataWeave Function: Send all properties as an object. If you need to add your custom headers you can use the next option as an example As a Table: Add headers one by one in Anypoint Studio. With Default Headers: Configure headers in HTTP Request configuration.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,integration",high
How do I configure SUPPORT - Modifying api_events.json?,"SUPPORT - Modifying api_events.json Last update: October 04, 2023 Location of the File The api_events.json file is located in the following directory path, relative to your Datadog installation directory: ```yaml $DD_INSTALLATION_DIR/datadog_checks/mulesoft_anypoint/vendor/integration_core/readers/mulesoft_anypoint/apis/api_events.json ``` Here, $DD_INSTALLATION_DIR represents the root directory of your Datadog installation. Purpose of the File The api_events.json file contains configuration data related to the metrics and events that the Mulesoft Anypoint Integration fetches. Each metric may have associated tags, one of which is resource_path. How to Modify the File Backup : As a best practice, always make a backup of the original api_events.json file before making any modifications. This ensures you have a fallback option in case of unintended changes. Access the file : Navigate to the directory provided above, relative to your Datadog installation directory. Open the api_events.json file in a text or code editor of your choice. Locate the ""resource_path"" tag : Within the file, search for instances of the tag ""resource_path"" under the tags_expr_str section for each metric. It will look something like this: ```yaml ""resource_path"": ""$[*].['Resource Path']"", ``` 4. Remove the tag : For each metric that contains the ""resource_path"" tag, remove the entire line for this tag. Ensure you also handle the comma appropriately to maintain the correct JSON format. Save and close : Once you've removed the ""resource_path"" tag from all metrics, save your changes and close the editor. Restart the Datadog Agent : Depending on your configuration and setup, you might need to restart the Datadog Agent to apply the changes. Please refer to Datadog's official documentation or your system's best practices for guidance on this step. Important Note: ð¨ Implications of Tag Removal : By removing the ""resource_path"" tag, if any dashboard or query uses this tag, it will be affected. The dashboard or query relying on this tag will no longer function as intended. ð¨ Maintaining JSON Structure : Ensure that the resulting api_events.json file maintains a valid JSON structure after the modification. Invalid or corrupted JSON can lead to malfunctions or loss of functionality in the Datadog Mulesoft Anypoint integration. Using online JSON validators or built- in features of JSON editors can help verify the structure.",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,integration,dashboard",high
How do I configure SUPPORT - Possible Errors?,"SUPPORT - Possible Errors Last update: July 17, 2024 Errors Updating to APM Connector 3.0.0 could cause you to face some type of errors and here we will explain how you can handle them. Null values When you define where your trace information is in your operation you need to specify from where to take it. This could bring some issues if you use DataWeave to resolve the value and that value is null. You will see the next error message in that case. 1.png?VersionId=roAxoFxvt7gdGR9.2E5fHfzLeOJtb1JK) How to handle this error? You can validate the value using a default value to avoid getting null. You can use the next DataWeave expression as an example Logs and traces not correlating If you are having the problem that your application does not show the relations with its logs could be due to they are not correlated correctly That means your Log4j2 configuration properties MUST match with your configuration set in your APM Global Configuration in next fields: - env - Service - Version Those three fields must match in order to show correctly the connection between logs and traces. Examples - The next is an example of a fully configured APM Connector with distributed tracing. - A create span connector with no distributed tracing, next is the general tab Distributed tracing tab",datadog-mulesoft-docs,"datadog,mulesoft,documentation,configuration,integration,apm",high
